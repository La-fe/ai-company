# RLHF Loop — CPO 产品规划质量自进化系统

## 核心理念

产品规划质量不靠"经验直觉"，靠**可量化的评估 + 持续的反馈循环**。

RLHF Loop 让 CPO 的每次 PRD 生成、版本规划、迭代评审都成为学习样本，持续提升规划质量。

区别于传统产品评审：
- 传统评审：主观判断"这个 PRD 写得不错"
- RLHF Loop：7 维度量化打分 → 归因分析 → 规则进化 → 下次更好

---

## RLHF Loop 架构

```
┌──────────────────────────────────────────────────────────┐
│                                                          │
│    ┌───────────┐    ┌───────────┐    ┌───────────┐      │
│    │ Generate  │───▶│ Evaluate  │───▶│ Feedback  │      │
│    │(生成规划) │    │(质量评估) │    │(反馈收集) │      │
│    └───────────┘    └───────────┘    └───────────┘      │
│          ▲                                │              │
│          │                                ▼              │
│    ┌───────────┐                    ┌───────────┐       │
│    │  Apply    │◀───────────────────│  Update   │       │
│    │(应用规则) │                    │(策略更新) │       │
│    └───────────┘                    └───────────┘       │
│          │                                │              │
│          │         ┌─────────────┐        │              │
│          └────────▶│ Consolidate │◀───────┘              │
│                    │  (整合优化) │                        │
│                    └─────────────┘                        │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

---

## 五阶段循环

### Phase 1: Generate（生成规划）

基于当前规则集和产品模板生成 PRD / 版本规划。

**输入：**
- CEO 下达的产品目标 + 约束条件
- 当前规则集（已学到的产品规划 best practice）
- 对应产品类型模板（website / landing-page / payment / ai-product）

**输出：**
- PRD 文档 / 版本规划文档
- 元数据：本次应用了哪些规则、使用了哪个模板

**关键：** 记录本次生成使用的规则 ID 和模板，便于后续归因。

### Phase 2: Evaluate（质量评估）

对生成的规划进行 7 维度量化评估。

**评估工具：** `product-eval-dimensions.md` 中的评分体系

**评估流程：**
1. 逐维度打分（1-10 分，有明确的 10/7/4/1 标准）
2. 加权计算总分
3. 检查一票否决项（Veto Rules）
4. 生成评估报告

**评估报告模板：**

```markdown
## 产品规划评估报告

### 基本信息
- 规划类型: [PRD / 版本规划 / 迭代评审]
- 产品类型: [SaaS / 电商 / 内容 / AI 产品]
- 评估时间: {date}
- 规划版本: {version}

### 评分结果

| # | 维度 | 权重 | 得分 | 加权分 | 关键发现 |
|---|------|------|------|--------|---------|
| 1 | 原子化程度 | 20% | x.x | x.xx | ... |
| 2 | MVP 精准度 | 18% | x.x | x.xx | ... |
| 3 | 用户场景覆盖 | 15% | x.x | x.xx | ... |
| 4 | 技术可行性 | 15% | x.x | x.xx | ... |
| 5 | 竞品差异化 | 10% | x.x | x.xx | ... |
| 6 | 指标可衡量性 | 12% | x.x | x.xx | ... |
| 7 | 迭代逻辑性 | 10% | x.x | x.xx | ... |
| **总分** | | **100%** | | **x.xx** | |

### 一票否决检查
- [ ] 原子化程度 ≥ 4 — PASS / FAIL
- [ ] MVP 精准度 ≥ 3 — PASS / FAIL
- [ ] 存在用户故事 — PASS / FAIL
- [ ] 并非所有功能都标 P0 — PASS / FAIL

### 风险点
1. [风险描述] — 影响: [高/中/低] — 建议: [...]
2. ...

### 改进建议
1. [具体、可操作的改进建议]
2. ...

### 决策
- **结论**: [通过 / 小幅修订 / 大幅修订 / 重做]
- **修订要求**: [如需修订，列出具体要求]
```

### Phase 3: Feedback（反馈收集）

收集显式和隐式反馈信号。

**显式反馈：**
- CEO 对 PRD 的评语和修改要求
- 开发团队对技术可行性的反馈
- 用户调研对需求假设的验证结果
- 复盘时发现的规划质量问题

**隐式反馈：**
- PRD 被要求修改的轮次（轮次越少越好）
- PRD 是否被 CEO 直接批准（无修改 = 强正向信号）
- 开发中是否因 PRD 不清晰导致返工
- 上线后指标是否达到 PRD 中的预期

**反馈信号量化：**

```
+1.0 = CEO 直接批准 + 上线达标
+0.5 = CEO 小修后批准
+0.0 = 大幅修订后通过
-0.5 = 需要重做
-1.0 = 方向性错误，整体推翻
```

### Phase 4: Update（策略更新）

根据评估得分和反馈信号更新规则集。

**规则得分计算：**

```
Score = Σ(applied_count × feedback_signal) / total_applications

反馈信号:
  +1.0 = CEO 直接批准 + 上线达标
  +0.5 = 小修后通过
  +0.0 = 大幅修订
  -0.5 = 需要重做
  -1.0 = 方向性推翻
```

**规则置信度：**

```
Confidence = 1 - 1/(applied_count + 1)

应用 1 次: Confidence = 50%
应用 5 次: Confidence = 83%
应用 10 次: Confidence = 91%
应用 20 次: Confidence = 95%
```

**规则更新策略：**

| 得分区间 | 置信度 | 操作 |
|---------|-------|------|
| > 0.7 | > 80% | **强化**：提升优先级，考虑泛化到其他产品类型 |
| 0.3 ~ 0.7 | > 80% | **保持**：继续观察，收集更多数据 |
| < 0.3 | > 80% | **弱化**：降低优先级，考虑淘汰或特化 |
| 任意 | < 50% | **探索**：增加应用机会以收集足够数据 |

**规则泛化（高分规则）：**
- 具体规则："AI 产品的 PRD 必须包含 fallback 方案"
- 泛化规则："任何依赖不确定性技术的产品必须包含 fallback 方案"

**规则特化（场景分裂）：**
- 原规则："MVP P0 功能不超过 5 个"
- 特化后："SaaS 产品 MVP P0 不超过 5 个；Landing Page 产品 P0 不超过 3 个"

### Phase 5: Consolidate（整合优化）

定期（每 5 次产品规划或用户主动触发）进行规则整合。

**整合操作：**

1. **去重合并** — 合并语义相似的规划规则
2. **冲突解决** — 发现矛盾规则，保留高分规则或按产品类型拆分
3. **模板更新** — 将高分规则沉淀到对应产品类型模板中
4. **死规则清理** — 删除长期未使用或持续低分的规则
5. **过拟合检测** — 识别过于具体、不可泛化的规则
6. **跨类型迁移** — 某个产品类型下高分的规则，尝试迁移到其他类型

---

## 触发时机

| 触发点 | 评估范围 | 重点维度 |
|--------|---------|---------|
| PRD 生成后 | 完整 7 维度评估 | 原子化、用户场景、MVP 精准度 |
| 版本规划后 | 侧重迭代维度 | 迭代逻辑性、技术可行性、指标可衡量性 |
| 每次迭代评审 | 对比计划 vs 实际 | 指标可衡量性、技术可行性 |
| CEO 审批反馈后 | 基于反馈更新规则 | 根据反馈信号确定 |
| 上线后数据回收 | 验证规划准确性 | 所有维度的回溯验证 |

---

## 决策分层

| 总分区间 | 决策 | 后续动作 |
|---------|------|---------|
| **≥ 8.0** | 通过 | 直接进入开发排期，记录正向反馈 |
| **7.0 - 7.9** | 小幅修订 | 针对低分维度修改后重新评估，不需要全部重做 |
| **6.0 - 6.9** | 大幅修订 | 重新审视核心假设和功能拆分，可能需要重新做用户调研 |
| **< 6.0** | 重做 | 回到问题定义阶段，重新理解需求和用户场景 |

**一票否决（任一触发即判定"重做"）：**
- 原子化程度 < 4
- MVP 精准度 < 3
- 无用户故事直接列功能
- 所有功能标 P0

---

## 数据结构

### 规则结构

```yaml
- id: cpo_rule_001
  category: 原子化
  content: "每个功能点应该可以独立开发、独立测试、独立上线"
  applies_to: [all]  # 或 [saas, ai-product] 等特定产品类型
  priority: high
  score: 0.85
  confidence: 0.91
  applied_count: 12
  positive_feedback: 9
  negative_feedback: 1
  neutral: 2
  created_at: 2025-01-10
  last_applied: 2025-01-20
  parent_rule: null
  child_rules: []
  conditions: []
  examples:
    good: ["用户注册 → 拆分为: 邮箱注册 / 第三方登录 / 密码找回"]
    bad: ["用户系统（包含注册、登录、权限、偏好设置）作为一个功能"]
```

### Episode 记录

```yaml
- episode_id: cpo_ep_001
  date: 2025-01-20
  type: prd_generation  # prd_generation / version_planning / iteration_review
  product_type: saas
  product_name: "AcmeCorp 数据看板"
  template_used: website
  rules_applied: [cpo_rule_001, cpo_rule_003, cpo_rule_007]
  eval_scores:
    atomization: 8.5
    mvp_precision: 7.0
    user_scenario: 9.0
    tech_feasibility: 7.5
    competitive_diff: 6.0
    metric_measurability: 8.0
    iteration_logic: 7.0
    weighted_total: 7.64
  veto_triggered: false
  decision: minor_revision
  revisions: 1
  final_approved: true
  feedback:
    ceo_signal: +0.5
    dev_signal: +0.5
    post_launch_signal: null  # 上线后回填
  implicit_signals:
    revision_count: 1
    ceo_approved: true
    dev_rework: false
```

---

## 冷启动策略

新产品线没有历史数据时：

1. **加载默认规则集**：来自 `prd-framework.md` 和 `version-planning.md` 的核心原则
2. **匹配产品模板**：根据产品类型加载 `templates/` 下对应模板
3. **前 3 次规划强制完整评估**：即使 CEO 直接通过，也执行全量 7 维度评估
4. **第 3 次后启用完整 RLHF Loop**：规则得分和置信度开始生效
5. **第 5 次后启用 Consolidate**：开始规则整合优化

---

## 进化报告模板

```markdown
## CPO 规划能力进化报告

**总规划次数：** X 次
**平均评估分：** X.X 分
**平均修改轮次：** X.X 轮
**CEO 直接通过率：** XX%

### 高分规则 TOP 5
1. [0.92] 每个功能点拆到可独立交付的最小单元
2. [0.88] MVP 只包含验证核心假设必需的功能
3. [0.85] 用户故事必须关联到具体 JTBD
4. [0.82] 复杂度评估使用 5 维度矩阵
5. [0.80] 每个成功指标必须有基线值和目标值

### 低分规则（待淘汰）
1. [0.25] 竞品有的功能都列为 P1 ← 建议删除
2. [0.30] 所有非功能需求放在 V1.2 ← 建议修正

### 模板改进建议
- AI 产品模板：增加"模型选型决策树"检查项
- Landing Page 模板：强化"single CTA"原则
- 支付模板：增加"合规检查"维度

### 跨产品类型发现
- 规则 #5（原子化拆分）在所有产品类型中均高分 → 提升为通用规则
- 规则 #12（A/B 测试前置）在 Landing Page 中高分但在 SaaS 中无效 → 特化
```

---

## 与 CEO RLHF 的协同

CPO 的 RLHF Loop 与 CEO 的评估系统形成闭环：

```
CEO 评估 CPO 规划质量
        ↓
CEO 反馈信号 → CPO RLHF 的 feedback_signal
        ↓
CPO 规则更新 → 下次规划质量提升
        ↓
CEO 再次评估 → 更高的通过率
```

CEO 评估中的"产品规划"维度分数，直接作为 CPO RLHF 的外部反馈信号输入。
