# AI 系统合约参考手册

> 本文档为 AI CPO Feature Design 的参考资料，在 Phase 6（AI 系统合约）时加载。
> 来源: OpenAI PRD Template (Miqdad Jaffer), CC/CD Framework, BVP AI Pricing Playbook

---

## AI 合约标准模板（增强版）

每个 AI 交互点都需要定义一份合约。合约是 AI 行为的"规格书"——从产品经理到工程师都应该对齐的共识。

### 完整模板

```yaml
名称: [AI 交互点名称]
触发: [用户什么操作触发这个 AI 交互]
输入:
  - [用户提供的输入1]
  - [系统上下文输入2]
  - [来自其他实体的数据3]
处理: [AI 做什么处理——不需要写 Prompt，而是写业务逻辑]
输出:
  格式: [结构化输出的 schema / 自由文本 / 选项列表]
  长度: [预期输出长度范围]
质量标准:
  - [可接受输出的定义]
  - [不可接受输出的定义]
降级方案: [AI 失败时的 fallback]
HITL 级别: [L1/L2/L3/L4]

# === 以下为增强字段 ===

评估规格:
  测量方法: [自动测试 / 人工评分 / 用户满意度]
  评估数据集:
    规模: [N 条标准输入]
    覆盖: [典型场景 X% + 边界 Y% + 对抗 Z%]
  上线阈值: [质量标准达到 X% 可以上线]
  持续监控: [上线后每 N 天重跑评估]

成本信封:
  单次 API 成本: [估算或实测 $X]
  输入 Token: [平均 N tokens]
  输出 Token: [平均 N tokens]
  月均调用数: [每用户每月预计调用 N 次]
  用户月成本: [单次成本 × 月均调用 = $X/用户/月]
  经济可行线: [超过 $X/用户/月 需要优化或限流]

延迟预算:
  最大延迟: [用户可接受的最长等待 Ns]
  策略: [流式输出 / 后台渲染 / 预生成]
  进度指示: [进度条 / 骨架屏 / 分步展示 / 打字机效果]

风险标记:
  可能出错: [幻觉 / 偏见 / 内容侵权 / 质量波动]
  检测方式: [自动检查 / 用户举报 / 定期审计]
  缓解策略: [过滤 / 人工审核 / 限制范围]
```

### 填写指南

**评估规格**:
- 测量方法选择: 生成类任务用人工评分 + 用户满意度，分类类任务用自动测试
- 评估数据集: 最少 50 条，理想 100+，必须覆盖产品实际会遇到的所有场景类型
- 上线阈值: 与能力分级对齐——可靠级要求 >95%，中等级要求 >70%

**成本信封**:
- 使用当前模型的 Token 单价估算
- 月均调用数从同类产品基准或保守估算（初期日活用户 × 日均调用次数）
- 经济可行线 = 订阅价格 × 目标毛利率 60% ÷ AI 功能数

**延迟预算**:
- 交互式操作: 最大 5s（用流式输出）
- 后台任务: 最大 60s（用异步 + 通知）
- 批量操作: 最大 5min（用进度条 + 后台执行）

**风险标记**:
- 每个合约至少标注 1 个风险
- 不标注不代表没风险，代表没想到（需要复审）

---

## 成本建模方法

### API 调用链分析

一个用户操作可能触发多次 API 调用。成本建模要分析完整调用链：

```
用户操作: "生成商业策略"
├── API 调用 1: 分析用户输入 (Claude Haiku, ~500 tokens)    $0.001
├── API 调用 2: 生成策略草稿 (Claude Sonnet, ~3000 tokens)  $0.015
├── API 调用 3: 质量检查 (Claude Haiku, ~1000 tokens)       $0.002
└── 总计: $0.018/次

用户月均使用: 20 次/月
用户月 AI 成本: $0.36/月
```

### 单用户月成本计算

```
单用户月 AI 成本 = Σ (每个 AI 功能的 单次成本 × 月均使用次数)
```

### 毛利影响分析

```
AI 产品毛利率 = (月订阅价 - 月 AI 成本 - 月基础设施成本) / 月订阅价

基准:
- 传统 SaaS: 80-90% 毛利
- AI 产品: 50-60% 毛利（因 API 成本高）
- 目标: AI 产品毛利 ≥ 60%
```

### 成本优化杠杆

| 杠杆 | 策略 | 预期效果 | 实施难度 |
|------|------|---------|---------|
| **模型分级** | 简单任务用 Haiku，复杂用 Sonnet | 成本降 50-70% | 低 |
| **缓存** | 相似输入复用结果 | 成本降 30-50% | 中 |
| **Prompt 精简** | 压缩 System Prompt | Token 降 20-40% | 低 |
| **批量合并** | 多个小请求合为一个 | 减少 overhead | 中 |
| **预生成** | 高频场景预先生成缓存 | 延迟降低 + 成本降低 | 高 |

---

## 评估数据集设计指南

### 数据集构成

| 类型 | 占比 | 目的 | 示例 |
|------|------|------|------|
| **典型场景** | 60% | 验证核心功能 | 正常用户输入、标准业务场景 |
| **边界场景** | 20% | 发现脆弱点 | 极短输入、极长输入、多语言、特殊字符 |
| **对抗场景** | 10% | 测试安全性 | Prompt Injection、有害内容、越界请求 |
| **回归场景** | 10% | 防止退化 | 历史 bug 的触发条件 |

### 评估数据集模板

```markdown
| # | 输入 | 场景类型 | 期望输出要求 | 评判标准 |
|---|------|---------|------------|---------|
| 1 | {输入} | 典型 | {输出应包含/满足} | [可接受/部分可接受/不可接受] |
| 2 | {输入} | 边界 | {输出应包含/满足} | [可接受/部分可接受/不可接受] |
```

---

## 参考来源

- Miqdad Jaffer: [AI Product Requirements Document Template](https://www.lennysnewsletter.com/p/ai-product-requirements-document)
- BVP: [AI Pricing Playbook](https://www.bvp.com/atlas/)
- Stripe: [AI Pricing Framework](https://stripe.com/guides/ai-pricing)
- Lenny's Newsletter: [CC/CD Framework](https://www.lennysnewsletter.com/)
