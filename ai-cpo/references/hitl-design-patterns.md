# HITL 设计模式参考手册

> 本文档为 AI CPO Feature Design 的参考资料，在 Phase 5（用户旅程 + HITL 设计）时加载。
> 来源: Stanford HAI, Smashing Magazine Agentic UX, Google Cloud Agentic Patterns

---

## HITL 4 级光谱

Human-in-the-Loop（HITL）不是二元选择（有人/无人），而是一个光谱。根据 AI 自主度和人类角色的不同，分为 4 级：

| 级别 | 模式 | AI 自主度 | 人类角色 | 适用场景 | 典型交互 |
|------|------|----------|---------|---------|---------|
| **L1** | AI 生成，人审核 | 低 | 审批者 | 高风险输出（产品方向、定价策略、法律文本） | AI 出草稿 → 人逐条审核 → 人修改后发布 |
| **L2** | AI 建议，人选择 | 中低 | 决策者 | 多选项场景（方案卡片、模板选择、A/B 方向） | AI 提供 3-5 个选项 → 人选一个 → AI 执行细化 |
| **L3** | AI 自主，人监督 | 中高 | 监督者 | 低风险重复操作（数据追踪、内容排期、格式转换） | AI 自动执行 → 人定期抽查 → 异常时人工介入 |
| **L4** | AI 自主执行 | 高 | 回顾者 | 后台任务（分析报告生成、推荐优化、日志处理） | AI 完全自主 → 人只看结果摘要 → 不满意时回退 |

### HITL 级别选择决策树

```
这个操作的后果严重吗？
├── 是（不可逆/高成本/影响用户）→ L1 或 L2
│   ├── 需要创造性判断？→ L1（人审核）
│   └── 有明确选项？→ L2（人选择）
└── 否（可逆/低成本/内部操作）→ L3 或 L4
    ├── 结果需要可见？→ L3（人监督）
    └── 纯后台？→ L4（人回顾）
```

---

## 渐进自主设计

用户对 AI 的信任需要**时间积累**。渐进自主 = 随着信任增长，逐步提高 AI 的自主度。

### 信任阶段与 HITL 映射

| 用户阶段 | 信任水平 | 推荐 HITL 级别 | 设计策略 |
|---------|---------|---------------|---------|
| **新用户**（注册 < 1 周） | 低 | L1 / L2 | AI 做建议，人做所有决策。展示 AI 思考过程 |
| **有首单用户**（完成首个核心任务） | 中低 | L2 / L3 | AI 可以自动执行简单任务，关键任务仍需确认 |
| **活跃用户**（使用 > 1 月） | 中高 | L3 为主 | 大部分操作 AI 自主，用户监督和抽查 |
| **成熟用户**（使用 > 3 月） | 高 | L3 / L4 | AI 高度自主，用户只关注异常和结果 |

### 升级触发条件

```markdown
L1 → L2: 用户连续 5 次未修改 AI 输出 → 提示"要不要让 AI 直接给你选项？"
L2 → L3: 用户连续 10 次选择了 AI 的第一推荐 → 提示"要不要让 AI 自动执行？"
L3 → L4: 用户 30 天内抽查率 < 5% → 提示"要不要让 AI 全自动？"
```

### 降级触发条件

```markdown
L4 → L3: 用户主动撤销 AI 操作 → 自动降回监督模式
L3 → L2: 用户连续 3 次否决 AI 自主操作 → 降回选择模式
L2 → L1: 用户对 AI 输出给差评 → 降回审核模式
```

---

## 失败路径设计

AI 不可能 100% 正确。用户不满意 AI 输出时，需要清晰的退出路径。

### 3 种失败处理模式

| 模式 | 适用场景 | 交互设计 | 成本 |
|------|---------|---------|------|
| **重新生成** | AI 输出方向对，细节不满意 | "换一个" 按钮，保留输入重新请求 | 低（1 次额外 API 调用） |
| **手动编辑** | AI 输出 80% 可用，需要微调 | 在 AI 输出上直接编辑，保存为最终版 | 零（用户操作） |
| **回退重来** | AI 输出完全偏离，需要换思路 | "从头开始" 按钮，清空 AI 上下文重新引导 | 高（用户时间 + 多次 API） |

### 失败路径设计原则

1. **永远有退路**: 每个 AI 输出旁边都必须有"手动完成"的入口
2. **保留用户输入**: AI 失败时不要丢弃用户已输入的信息
3. **明确告知状态**: "AI 无法完成此任务"比"出错了"更有用
4. **收集失败数据**: 每次失败都是改进 AI 的信号

---

## 关键时刻（Moments of Truth）

关键时刻 = 决定用户去留的 2-3 个触点。在这些触点上，AI 表现的好坏直接决定转化和留存。

### 识别方法

1. **画出用户旅程**: 从首次触达到持续使用的完整路径
2. **标注情感曲线**: 每一步用户的信心/兴趣是上升还是下降
3. **找拐点**: 信心急剧变化的点 = 关键时刻
4. **验证**: 这个点失败后，用户是继续还是离开？

### 常见关键时刻

| 时刻 | 发生阶段 | 用户期望 | 失败后果 |
|------|---------|---------|---------|
| **首次 AI 输出** | Onboarding | "AI 真的能帮到我" | 流失（"不过如此"） |
| **首次真实使用** | 激活 | "用在我的真实场景也好用" | 流失（"只是 Demo 好用"） |
| **首次犯错** | 使用中期 | "出错了能补救" | 信任崩塌（"不可靠"） |

---

## 信任建设渐进模型

信任不是一次建立的，而是通过四个阶段逐步积累：

```
展示 → 解释 → 控制 → 委托
```

| 阶段 | 做什么 | AI 行为 | 用户感受 |
|------|--------|--------|---------|
| **展示** | 展示 AI 能做什么 | 用真实案例 Demo | "看起来不错" |
| **解释** | 解释 AI 是怎么做的 | 展示推理过程、引用来源 | "我理解它的逻辑" |
| **控制** | 给用户控制权 | 允许调整参数、修改输出、设置偏好 | "我能掌控它" |
| **委托** | 用户信任到可以放手 | AI 自主执行，用户看摘要 | "它比我自己做更好" |

### 每个阶段的设计要点

- **展示**: Demo 必须用用户自己的数据，不是 toy example
- **解释**: 不需要完全透明（不是看代码），而是"大致逻辑可理解"
- **控制**: 提供"粗调"（方向选择）而非"细调"（参数滑块），降低认知负担
- **委托**: 即使委托了，也要有"紧急停止"按钮

---

## 参考来源

- Stanford HAI: [Human-in-the-Loop AI](https://hai.stanford.edu/)
- Smashing Magazine: [Designing Agentic UX (2026)](https://www.smashingmagazine.com/)
- Google Cloud: [Agentic Design Patterns](https://cloud.google.com/blog/products/ai-machine-learning/)
- Nielsen Norman Group: [AI UX Guidelines](https://www.nngroup.com/articles/ai-ux/)
