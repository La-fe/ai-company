# Phase A: 发现过程

```
═══════════════════════════════════════════════════════════
 Phase A: 发现过程 — 从模糊到清晰
 思维模式: 发散→收敛，允许推翻假设
═══════════════════════════════════════════════════════════
```

### Phase 1: 问题锚定（JTBD + 挣扎时刻）

> 读取参考: `{PLUGIN_ROOT}/references/problem-grounding.md`

**Step 1.1: 宏观→微观 JTBD 拆解**

从 company.md 的宏观 JTBD 出发，为每个产品概念拆解微观 JTBD：

每个微观 JTBD 包含三维度：
- 功能性任务（Practical）：用户要完成什么操作？
- 情感性任务（Emotional）：用户想要什么感受？
- 社会性任务（Social）：用户想要什么形象？

**Step 1.2: 挣扎时刻定义**

为每个概念定义挣扎时刻——用户在哪里卡住、放弃、选择替代方案。使用 4 种力量模型分析：

- Push（推力）：现有方案的痛苦
- Pull（拉力）：新方案的吸引力
- Anxiety（焦虑）：对新方案的不确定
- Inertia（惯性）：现有方案的习惯

**Step 1.3: 反定位验证**

建立"不做"清单——哪些方向虽然相关但不做，以及为什么。

**Step 1.4: 输出**

写入 `{output_dir}/feature-spec.md` > `## Step 1: 问题锚定`

**WAIT**

```
问题锚定完成。请审阅 feature-spec.md 中的 JTBD 拆解和挣扎时刻：

1. 微观 JTBD 是否准确反映了你对每个概念的理解？
2. 挣扎时刻的描述是否贴合你观察到的用户行为？
3. "不做"清单是否有遗漏或误判？

请提供修改意见，或回复"继续"进入 AI 能力评估。
```

---

### Phase 2: AI 能力评估（Capability-First）

> 读取参考: `{PLUGIN_ROOT}/references/ai-capability-assessment.md`

**Step 2.1: 列出 AI 能力清单**

基于微观 JTBD，列出产品依赖的所有 AI 能力。

**Step 2.2: 评估可靠度**

对每个 AI 能力进行 3 级评估：
- **可靠** (>95%): 可以默认启用，无需人工审核
- **中等** (70-95%): 需要人工审核或用户确认
- **实验** (<70%): 只能作为建议/灵感，不能作为核心流程

**Step 2.3: 标注硬边界**

标注 AI 当前做不到的事（实时数据、保证准确性、原创性验证等）。

**Step 2.4: 能力→JTBD 映射**

建立映射表：哪些 JTBD 的 AI 能力可靠 → 可以自动化；哪些不可靠 → 需要人类 fallback。

**Step 2.5: 输出**

写入 `{output_dir}/feature-spec.md` > `## Step 2: AI 能力评估`

**WAIT**

```
AI 能力评估完成。请审阅：

1. 能力分级是否合理？有没有你认为高估/低估的能力？
2. 硬边界清单是否完整？
3. 能力→JTBD 映射的结论是否可接受？

请提供修改意见，或回复"继续"进入竞品数据模型提取。
```

---

### Phase 3: 竞品综合评估

> 读取参考: `{PLUGIN_ROOT}/references/data-model-extraction.md`（共性分析部分）

**前置条件**: `{context_dir}/competitors/*.md` 已存在（由 `/cpo-competitor-deep` 产出的 5 层深度分析档案）。

**Step 3.1: 读取所有竞品 5 层分析档案**

```bash
ls {context_dir}/competitors/*.md
```

- 如果存在 ≥ 2 个档案 → 读取所有档案，提取每个竞品的 5 层分析数据
- 如果存在但 < 2 个 → 提示："当前仅有 N 个竞品档案，建议用 `/cpo-competitor-deep` 补充分析更多竞品后再继续"
- 如果不存在 → 提示："请先用 `/cpo-competitor-deep {竞品名}` 分析至少 2 个竞品，再运行 feature-design"

**Step 3.2: 跨竞品模式识别**

基于所有竞品的 5 层档案，进行跨竞品横向对比：

- **实体共性矩阵**

| 实体 | 竞品覆盖度 | 共性程度 | 说明 | 对我的启示 |
|------|-----------|---------|------|-----------|
| [从各竞品 Layer 2 汇总] | N/M 个竞品有 | 核心/多数/少数/空白 | [差异说明] | [设计建议] |

- **数据模型复杂度梯度**：从简单（如 Stan Store 的扁平模型）到复杂（如 Whop 的多层嵌套），分析复杂度与目标用户的关系
- **用户旅程模式对比**：模板式 / 问答式 / 空白画布 / AI 生成，各竞品 Onboarding 设计的共性和差异
- **AI 能力覆盖度对比**：哪些竞品有 AI 功能、AI 做到什么程度、HITL 级别差异

**Step 3.3: 空白分析（带推导过程）**

每个空白必须有完整推导链：

| 空白 | 哪些竞品缺少 | 为什么没做（推测） | 我方可行性 | 差异化价值 |
|------|------------|------------------|-----------|-----------|
| [空白实体/功能] | [列举缺少的竞品] | [技术限制/市场选择/ROI不足] | [基于 Step 2 AI 能力评估] | [用户价值判断] |

**Step 3.4: 对自身产品设计的启示**

从竞品模式中推导自身产品的设计方向：

- **实体设计建议**：从竞品共性实体推导"我也应该有的实体"，从空白推导"我的差异化实体"
- **旅程设计建议**：从竞品 Onboarding 模式推导"首次体验应该怎么走"，对比 TTFV
- **定价策略建议**：从竞品定价提取安全区间（价格带、免费层边界、核心付费壁垒）
- **差异化方向**：空白 × 我方 AI 能力 = 机会矩阵

**Step 3.5: 输出**

写入 `{output_dir}/feature-spec.md` > `## Step 3: 竞品综合评估`

**WAIT**

```
竞品综合评估完成。请审阅：

1. 跨竞品模式识别是否准确？
2. 空白分析的推导过程是否有说服力？
3. 对自身的设计启示是否合理？

请提供修改意见，或回复"继续"进入自身数据模型设计。
```

---

### Phase 4: 自身数据模型设计

> 继续使用: `{PLUGIN_ROOT}/references/data-model-extraction.md`（限界上下文 + AI 原生实体部分）

**Step 4.1: 核心实体设计**

基于 JTBD + 能力评估 + 竞品空白，设计核心实体。

**Step 4.2: 限界上下文标注**

标注哪些实体归一组（同一个词在不同场景含义不同 → 拆分上下文）。

**Step 4.3: AI 原生实体标注**

标注只因 AI 存在的实体 = 差异化源 = 需要重点投资。

**Step 4.4: 领域事件目录**

列出核心领域事件（名词=实体，动词=事件），标注触发者（人/AI/系统）。

**Step 4.5: 输出**

写入 `{output_dir}/feature-spec.md` > `## Step 4: 数据模型`

**WAIT**

```
数据模型设计完成。请审阅：

1. 核心实体是否覆盖了所有关键业务概念？
2. 限界上下文的拆分是否合理？
3. AI 原生实体是否是你认为的差异化关键？
4. 领域事件目录是否完整？

请提供修改意见，或回复"继续"。
```

**Analyze 模式终止点**:
```
如果 --mode == analyze:
  ├── 停止执行。不读取 PHASE-B.md。
  ├── 更新 feature-spec.md header: > 完成度: Step 1-4 已完成
  └── 跳转到 SKILL.md Phase 10（下一步引导）

如果 --mode == design:
  └── 继续 → 读取 PHASE-B.md，执行 Phase 5
```
