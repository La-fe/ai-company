# AI 管线模式与评估框架

> 本文档在 Layer 6（AI 管线）时加载。
> 来源: AI Engineering, LLM Application Patterns, MLOps
> 层级对应: Layer 6 AI 管线

---

## AI 编排模式

### 模式分类

| 模式 | 核心思路 | 适用场景 | 复杂度 | 延迟 |
|------|---------|---------|--------|------|
| **单次调用** | 一个请求，一个响应 | 简单生成任务 | 低 | 低 |
| **串行链** | A→B→C 顺序执行 | 多步骤处理 | 中 | 高（累加） |
| **并行扇出** | 同时发起多个调用 | 多角度生成 | 中 | 取决于最慢 |
| **条件路由** | 根据条件选择不同路径 | 任务分类后处理 | 中 | 取决于路径 |
| **循环迭代** | 生成→评估→改进循环 | 质量要求高的生成 | 高 | 高（N×单次） |
| **Agent 循环** | 规划→执行→观察→调整 | 复杂自主任务 | 高 | 不可预测 |
| **RAG** | 检索→增强→生成 | 知识密集型任务 | 中 | 中 |
| **Map-Reduce** | 分割→并行处理→合并 | 大文档/批量处理 | 中 | 取决于分片数 |

### 模式选择决策

```
编排模式决策树:
├── 一次 AI 调用能完成？
│   ├── 是 → 单次调用
│   └── 否 → 继续
├── 步骤之间有依赖？
│   ├── 严格顺序 → 串行链
│   ├── 互不依赖 → 并行扇出
│   └── 条件分支 → 条件路由
├── 需要质量迭代？
│   ├── 是 → 循环迭代（设置最大轮次）
│   └── 否 → 继续
├── 需要外部知识？
│   ├── 是 → RAG
│   └── 否 → 继续
├── 输入超大？
│   ├── 是 → Map-Reduce
│   └── 否 → 继续
└── 需要自主决策？
    ├── 是 → Agent 循环
    └── 否 → 串行链足够
```

### 各模式 ASCII 架构图

**单次调用**
```
[输入] ──→ [提示词组装] ──→ [模型API] ──→ [输出处理] ──→ [结果]
```

**串行链**
```
[输入] ──→ [Step1: 分析] ──→ [Step2: 生成] ──→ [Step3: 优化] ──→ [结果]
              │                  │                  │
              └─ 模型A           └─ 模型B           └─ 模型C
```

**并行扇出**
```
                ┌──→ [任务A: 文案] ──→┐
[输入] ──→ [拆分] ──→ [任务B: 图片] ──→ [合并] ──→ [结果]
                └──→ [任务C: SEO]  ──→┘
```

**条件路由**
```
[输入] ──→ [分类器] ──→┬── "类型A" ──→ [处理A] ──→ [结果]
                       ├── "类型B" ──→ [处理B] ──→ [结果]
                       └── "类型C" ──→ [处理C] ──→ [结果]
```

**RAG**
```
[用户查询] ──→ [向量化] ──→ [向量检索] ──→ [上下文组装] ──→ [生成] ──→ [结果]
                              │                │
                              ▼                ▼
                         ◆ 向量库        [检索到的文档]
```

---

## 模型选择框架

### 任务类型 → 模型族映射

| 任务类型 | 推荐模型族 | 关键考量 | 典型模型 |
|---------|-----------|---------|---------|
| **长文本生成** | 大语言模型 | 质量 > 速度 | Claude Sonnet/Opus, GPT-4o |
| **短文本生成** | 中等模型 | 速度 + 质量平衡 | Claude Haiku, GPT-4o-mini |
| **代码生成** | 代码特化模型 | 准确性 | Claude Sonnet, GPT-4o |
| **结构化提取** | 中等模型 | 格式一致性 | Claude Haiku + JSON Mode |
| **分类/路由** | 小模型 | 速度 + 低成本 | Claude Haiku, GPT-4o-mini |
| **图片生成** | 图像模型 | 质量 + 风格控制 | DALL-E 3, Midjourney, Flux |
| **图片理解** | 多模态模型 | 理解准确性 | Claude Sonnet, GPT-4o |
| **语音** | 语音模型 | 自然度 | Whisper, ElevenLabs, TTS |
| **嵌入/检索** | 嵌入模型 | 检索准确性 | text-embedding-3, Cohere |

### 模型选择决策

```
模型选择决策:
├── 质量最重要（用户直接看到结果）？
│   ├── 是 → 大模型（Sonnet/GPT-4o）
│   └── 否 → 继续
├── 需要极低延迟（<1s）？
│   ├── 是 → 小模型（Haiku/4o-mini）
│   └── 否 → 继续
├── 调用量很大（>10K/天）？
│   ├── 是 → 小模型 + 缓存
│   └── 否 → 中等模型
└── 需要最新知识？
    ├── 是 → RAG + 任意模型
    └── 否 → 直接生成
```

---

## HITL（Human-in-the-Loop）设计模式

### 5 级参与度

| 等级 | 用户参与 | 产品表现 | 适用场景 |
|------|---------|---------|---------|
| **自动** | AI 输出直接生效 | 用户可事后查看/修改 | 高可靠度功能（SEO meta） |
| **审核** | AI 输出后需确认 | "确认"/"编辑"按钮 | 重要但 AI 较可靠（文案） |
| **选择** | AI 提供多选项 | 2-3 个方案卡片 | 审美/偏好类（模板选择） |
| **协作** | AI 草稿 + 用户编辑 | 富文本编辑器 + AI 建议 | 需要个性化（产品描述） |
| **灵感** | AI 仅提供参考 | 侧边栏建议 | AI 不够可靠（定价策略） |

### HITL 设计决策

```
HITL 等级决策:
├── AI 输出可靠度 > 95%？
│   ├── 是 → 自动（事后可改）
│   └── 否 → 继续
├── 输出涉及金钱/发布？
│   ├── 是 → 至少审核级
│   └── 否 → 继续
├── 输出有审美偏好？
│   ├── 是 → 选择级（多方案）
│   └── 否 → 继续
├── 用户需要个性化？
│   ├── 是 → 协作级
│   └── 否 → 审核级
└── AI 可靠度 < 70%？
    ├── 是 → 灵感级（仅参考）
    └── 否 → 选择或协作级
```

### 确认点设计原则

- **关键节点确认**: 涉及金钱、发布、不可逆操作必须确认
- **批量操作减少确认**: 多个 AI 输出可以一次确认
- **渐进式信任**: 新用户多确认，老用户减少确认
- **确认 ≠ 阻塞**: 确认可以异步（先用默认，后台等确认）

---

## 降级策略模式

### 降级层级

| 层级 | 策略 | 适用场景 | 用户体验 |
|------|------|---------|---------|
| **热备** | 切换到备用模型 | 主模型不可用 | 无感知 |
| **缓存** | 返回缓存的类似结果 | 相似请求 | 轻微差异 |
| **模板** | 使用预设模板填充 | AI 生成失败 | 明显降级 |
| **手动** | 回退到手动操作 | 全部 AI 不可用 | 完全降级 |
| **排队** | 加入队列稍后处理 | 临时过载 | 延迟增加 |

### 降级决策

```
降级策略决策:
├── AI 是核心功能（无AI不可用）？
│   ├── 是 → 必须有热备 + 模板降级
│   └── 否 → 手动回退即可
├── 有相似历史结果？
│   ├── 是 → 缓存降级
│   └── 否 → 模板降级
├── 可以延迟处理？
│   ├── 是 → 排队降级
│   └── 否 → 立即降级
└── 多个 AI 能力？
    └── 每个能力独立降级，不要一个挂全挂
```

---

## 成本估算框架

### 计算公式

```
单次调用成本 = (输入 Token × 输入单价) + (输出 Token × 输出单价)

月度成本 = 单次调用成本 × 月调用次数

月调用次数 = 月活用户 × 每用户平均调用次数
```

### Token 估算参考

| 内容类型 | 大约 Token 数 |
|---------|-------------|
| 一个中文字 | ~1.5 token |
| 一个英文单词 | ~1.3 token |
| 一段产品描述（200字） | ~300 token |
| 一篇文章（2000字） | ~3000 token |
| 一个网页 HTML | ~2000-5000 token |
| 系统提示词 | ~500-2000 token |

### 成本估算模板

```markdown
### AI 成本估算（按 {N} 用户/月）

| AI 能力 | 调用频率 | 输入Token | 输出Token | 模型 | 单价(入/出) | 月成本 |
|---------|---------|----------|----------|------|-----------|--------|
| {能力A} | {N}次/月 | ~{N} | ~{N} | {模型} | ${X}/${Y}/1M | ${估算} |
| {能力B} | {N}次/月 | ~{N} | ~{N} | {模型} | ${X}/${Y}/1M | ${估算} |
| **合计** | | | | | | **${总计}** |

缓存命中率 {X}% 后实际成本: ${实际}
```

### 优化策略

| 策略 | 节省比例 | 适用场景 |
|------|---------|---------|
| **提示词缓存** | 60-90% | 系统提示词重复率高 |
| **结果缓存** | 30-70% | 相似输入产生相似输出 |
| **模型降级** | 50-80% | 非关键任务用小模型 |
| **批量处理** | 20-50% | 可延迟的任务合并处理 |
| **Token 优化** | 10-30% | 精简提示词、压缩上下文 |
| **异步批处理 API** | ~50% | 延迟容忍度高的任务 |

---

## AI 管线架构图模板

### 标准 AI 管线结构

```
[用户请求]
    │
    ▼
[请求路由] ── 根据请求类型分发
    │
    ├──→ [提示词管理]
    │         │
    │         ├── 模板库（按任务类型）
    │         └── 版本管理
    │
    ├──→ [上下文组装]
    │         │
    │         ├── 用户上下文（历史、偏好）
    │         ├── 业务上下文（产品数据、配置）
    │         └── 检索上下文（RAG，可选）
    │
    ├──→ [模型路由]
    │         │
    │         ├── 按任务类型选模型
    │         ├── 按优先级选模型（热备）
    │         └── 按成本选模型（降级）
    │
    ├──→ [调用执行]
    │         │
    │         ├── 同步调用（实时场景）
    │         ├── 流式调用（长文本生成）
    │         └── 异步调用（批量/离线）
    │
    ├──→ [输出处理]
    │         │
    │         ├── 格式验证/转换
    │         ├── 内容安全检查
    │         └── 结果缓存
    │
    └──→ [监控层]
              │
              ├── 延迟监控
              ├── 成本追踪
              ├── 质量采样
              └── 错误告警
```

---

## 质量标准

### AI 管线分析最低要求

| 维度 | 最低标准 |
|------|---------|
| AI 能力点数量 | 识别所有涉及 AI 的功能点 |
| 每个能力点有完整合约 | 输入/输出/编排/HITL/降级 全填 |
| 模型选择有理由 | 不只说"用 GPT-4"，要说"因为 X" |
| 成本估算 | 至少有数量级估算（$10/月 vs $100/月 vs $1000/月） |
| 降级方案 | 每个核心 AI 功能有降级路径 |
| 管线架构图 | 至少 1 张整体 AI 管线图 |

### 红线

- 不允许没有降级方案的核心 AI 功能
- 不允许没有成本估算的 AI 管线
- 不允许混淆"核心依赖"和"可选增强"的 AI 功能
